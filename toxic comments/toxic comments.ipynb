{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a2fac5",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d5486",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "<div> <b>Цель исследования:</b><br>\n",
    "    1. Построить различные модели классификации коментариев <br>\n",
    "    2. Добиться значения F1 не ниже 0.75<br><br>\n",
    "    <b>Ход исследования:</b><br>\n",
    "    1. Загрузка и пердобработка данных<br>\n",
    "    2. Построение моделей<br>\n",
    "    3. Пулучение нужного результата и анализ моделей<br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099caf03",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf5fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29be5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193875ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159287  \":::::And for the second time of asking, when ...      0\n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290  And it looks like it was actually you who put ...      0\n",
       "159291  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab873da",
   "metadata": {},
   "source": [
    "Почистим от лишних символов и лематизируем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf38d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize(text):\n",
    "\n",
    "    word_list = nlp(text)\n",
    "    lemmatized_output = ' '.join([token.lemma_ for token in word_list])\n",
    "        \n",
    "    return lemmatized_output\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    c = re.sub(r'[^a-zA-Z \\']', ' ', text)\n",
    "    c = ' '.join(c.split())\n",
    "    return(c.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6102f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_text'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a73ec6",
   "metadata": {},
   "source": [
    "Удалим не содержательные строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655061dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>c_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>193.61.111.53  15:00</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>64.86.141.133\"</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>~ \\n\\n68.193.147.157</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38743</th>\n",
       "      <td>88.104.31.21\"</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52336</th>\n",
       "      <td>14:53,</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53679</th>\n",
       "      <td>92.24.199.233|92.24.199.233]]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61644</th>\n",
       "      <td>\"\\n\\n 199.209.144.211  \"</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119018</th>\n",
       "      <td>\"\"\"</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137400</th>\n",
       "      <td>== \"\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic c_text\n",
       "4475    1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n...      0       \n",
       "6289                                 193.61.111.53  15:00      0       \n",
       "10193                                      64.86.141.133\"      0       \n",
       "17280                                ~ \\n\\n68.193.147.157      0       \n",
       "38743                                       88.104.31.21\"      0       \n",
       "52336                                              14:53,      0       \n",
       "53679                       92.24.199.233|92.24.199.233]]      0       \n",
       "61644                            \"\\n\\n 199.209.144.211  \"      0       \n",
       "119018                                                \"\"\"      1       \n",
       "137400                                             == \"\"\"      0       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['c_text'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f389b455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159282, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['c_text'] != '']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c89a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dec469ae7684b96a0cc2e59d43d01d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\programs\\Temp\\ipykernel_2380\\2562809883.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lemm_text'] = df['c_text'].progress_apply(lemmatize)\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df['lemm_text'] = df['c_text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dad7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['toxic', 'lemm_text']]\n",
    "df.to_csv('toxic_comments_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a753aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments_lemm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12118bd",
   "metadata": {},
   "source": [
    "Поделим получившиеся данные на трейн, тест и валидайию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f25e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, test = train_test_split(df, test_size=0.20, random_state=123, stratify=df['toxic'])\n",
    "train, valid = train_test_split(train_full, test_size=0.20, random_state=123, stratify=train_full['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fc750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(nlp, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cccf9",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2237d1",
   "metadata": {},
   "source": [
    "Обучим TF-IDF на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387ea1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = train['lemm_text'].values.astype('U')\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "tf_idf = TfidfVectorizer(stop_words=stopwords).fit(train['lemm_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc33fb9",
   "metadata": {},
   "source": [
    "Обучим несколько моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1cd61",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00d2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf_idf.transform(train['lemm_text'])\n",
    "y = train['toxic']\n",
    "val = tf_idf.transform(valid['lemm_text'])\n",
    "f_1 = 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2b6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf57fcd16b34566a1a830ed2879e800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in notebook.tqdm(range(3,6)):\n",
    "    model = LogisticRegression(penalty = 'l1', class_weight = 'balanced', random_state=123, solver='liblinear', C = c, max_iter=200)\n",
    "    model.fit(X, y)\n",
    "    f = f1_score(valid['toxic'], model.predict(val))\n",
    "    if f > f_1:\n",
    "        model_lin = model\n",
    "        f_1 = f\n",
    "        alpha = c\n",
    "print(f_1, alpha, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c762fc",
   "metadata": {},
   "source": [
    "Метрика удавлетворяет поставленной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0397530",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0625d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739881764438381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf_idf.transform(train['lemm_text'])\n",
    "y = train['toxic']\n",
    "\n",
    "model = CatBoostClassifier(iterations=300, verbose=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "f1_score(valid['toxic'], model.predict(tf_idf.transform(valid['lemm_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8878c",
   "metadata": {},
   "source": [
    "Метрика на валидации не удовлетворяет поставленной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d6444",
   "metadata": {},
   "source": [
    "### CatBoost внутренний метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f1764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.22386\n",
      "0:\tlearn: 0.4502146\ttotal: 77.8ms\tremaining: 23.3s\n",
      "100:\tlearn: 0.1081248\ttotal: 9.17s\tremaining: 18.1s\n",
      "200:\tlearn: 0.0958787\ttotal: 18.2s\tremaining: 8.97s\n",
      "299:\tlearn: 0.0886615\ttotal: 27.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7815896015341999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=300, text_features = ['lemm_text'], verbose=0)\n",
    "model.fit(train.drop(['toxic'],axis=1), train['toxic'])\n",
    "\n",
    "f1_score(valid['toxic'], model.predict(valid.drop(['toxic'],axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcba5f3",
   "metadata": {},
   "source": [
    "Данная модель показывает лучший результат на валидации. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c9793",
   "metadata": {},
   "source": [
    "## Тест\n",
    "\n",
    "Протестируем лучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d12cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.246246\n",
      "0:\tlearn: 0.3949720\ttotal: 480ms\tremaining: 2m 23s\n",
      "100:\tlearn: 0.1082417\ttotal: 49.5s\tremaining: 1m 37s\n",
      "200:\tlearn: 0.0976452\ttotal: 1m 37s\tremaining: 48.3s\n",
      "299:\tlearn: 0.0902273\ttotal: 2m 26s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7920054200542005"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=300, text_features = ['lemm_text'], verbose=100)\n",
    "model.fit(train_full.drop(['toxic'],axis=1), train_full['toxic'])\n",
    "\n",
    "f1_score(test['toxic'], model.predict(test.drop(['toxic'],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bd872aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76451476197203"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords).fit(train_full['lemm_text'])\n",
    "X = tf_idf.transform(train_full['lemm_text'])\n",
    "y = train_full['toxic']\n",
    "val = tf_idf.transform(test['lemm_text'])\n",
    "model_lin.fit(X,y)\n",
    "f1_score(test['toxic'], model_lin.predict(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7f65e",
   "metadata": {},
   "source": [
    "Логистическая регрессия также показывает неплохой результат на TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b761e5",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566afd3b",
   "metadata": {},
   "source": [
    "Были даны размеченные данные с коментариями пользователей. Проведена чистка текстов и их лематизация с помощью spacy. Удалены не заначащие коментарии. \n",
    "\n",
    "Были обучены 2 модели (LogisticRegression и CatBoostClassifier) на TF-IDF. CatBoost получила необходимую точность на валидации. \n",
    "\n",
    "Также была обучена модель CatBoostClassifier с внутренним методом обработки текста. Данная модель показала лучшую точность. На тесте метрика F1 получилась 0.79."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
